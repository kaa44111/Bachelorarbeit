{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba25b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# 1. Definitions: Directories and Parameters\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Root folders for original datasets\n",
    "DATA_ROOT = \"data\"\n",
    "DOMAINS = [\"Dichtflächen\", \"Bonding\", \"Wirecheck\"]\n",
    "\n",
    "# Each domain has subfolders: IO (only if present) and NIO\n",
    "# Example structure:\n",
    "# datasets/Dichtflächen/IO/\n",
    "# datasets/Dichtflächen/NIO/\n",
    "# datasets/Bonding/IO/\n",
    "# datasets/Bonding/NIO/\n",
    "# datasets/Wirecheck/NIO/  (no IO)\n",
    "\n",
    "# Output folder for patches\n",
    "PATCH_ROOT = \"patches\"\n",
    "PATCH_SIZE = 256\n",
    "STRIDE = 128  # 50% overlap\n",
    "\n",
    "# Augmentation pipeline (for training)\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# 2. Helper Function: Extract patches from one image and its mask\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "def extract_patches(image, mask, patch_size=PATCH_SIZE, stride=STRIDE):\n",
    "    \"\"\"\n",
    "    Splits a (H, W, C) image and its (H, W) mask into overlapping patches.\n",
    "    Returns a list of tuples: (img_patch, mask_patch, y, x).\n",
    "    y and x are the top-left coordinates of the patch in the original image.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    h, w = image.shape[:2]\n",
    "    for y in range(0, h - patch_size + 1, stride):\n",
    "        for x in range(0, w - patch_size + 1, stride):\n",
    "            img_patch = image[y:y + patch_size, x:x + patch_size]\n",
    "            mask_patch = mask[y:y + patch_size, x:x + patch_size]\n",
    "            patches.append((img_patch, mask_patch, y, x))\n",
    "    return patches\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 3. Step 1: Create patch directories and extract all patches\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Ensure patch output directories exist\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for subfolder in [\"images\", \"masks\"]:\n",
    "        os.makedirs(os.path.join(PATCH_ROOT, split, subfolder), exist_ok=True)\n",
    "\n",
    "# We'll build a DataFrame with columns:\n",
    "# ['patch_path', 'mask_path', 'label', 'domain', 'orig_image', 'y', 'x']\n",
    "records = []\n",
    "\n",
    "# Iterate over domains\n",
    "for domain_id, domain in enumerate(DOMAINS):\n",
    "    domain_folder = os.path.join(DATA_ROOT, domain)\n",
    "    \n",
    "    # Paths for NIO; a mask file is assumed to exist next to the image with the same base name\n",
    "    nio_folder = os.path.join(domain_folder, \"NIO\")\n",
    "    # IO folder may not exist for Wirecheck\n",
    "    io_folder = os.path.join(domain_folder, \"IO\") if os.path.isdir(os.path.join(domain_folder, \"IO\")) else None\n",
    "    \n",
    "    # Process NIO images first\n",
    "    for fname in os.listdir(nio_folder):\n",
    "        if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\")):\n",
    "            continue\n",
    "        img_path = os.path.join(nio_folder, fname)\n",
    "        # Assume mask has same name but in a \"Masks\" folder or with \"_mask\" suffix; adjust as needed\n",
    "        # Example: if mask files are in a subfolder \"masks\" inside the domain folder:\n",
    "        mask_name = os.path.splitext(fname)[0] + \"_mask.png\"\n",
    "        mask_path = os.path.join(domain_folder, \"Masks\", mask_name)\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Mask not found for {img_path}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        patches = extract_patches(image, mask)\n",
    "        for img_patch, mask_patch, y, x in patches:\n",
    "            # Determine label: if any pixel in mask_patch > 0, label = NIO (1), else IO (0)\n",
    "            label = 1 if np.any(mask_patch > 0) else 0\n",
    "            \n",
    "            # Determine which split this original image belongs to later (we'll assign splits after gathering all records)\n",
    "            records.append({\n",
    "                \"img_patch\": img_patch,\n",
    "                \"mask_patch\": mask_patch,\n",
    "                \"label\": label,\n",
    "                \"domain\": domain,\n",
    "                \"orig_image\": fname,\n",
    "                \"y\": y,\n",
    "                \"x\": x\n",
    "            })\n",
    "    \n",
    "    # Process IO images if folder exists (skip for Wirecheck)\n",
    "    if io_folder:\n",
    "        for fname in os.listdir(io_folder):\n",
    "            if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\")):\n",
    "                continue\n",
    "            img_path = os.path.join(io_folder, fname)\n",
    "            # For IO images, create an empty mask (all zeros)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            h, w = image.shape[:2]\n",
    "            mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            \n",
    "            patches = extract_patches(image, mask)\n",
    "            for img_patch, mask_patch, y, x in patches:\n",
    "                # All patches are IO (0)\n",
    "                records.append({\n",
    "                    \"img_patch\": img_patch,\n",
    "                    \"mask_patch\": mask_patch,\n",
    "                    \"label\": 0,\n",
    "                    \"domain\": domain,\n",
    "                    \"orig_image\": fname,\n",
    "                    \"y\": y,\n",
    "                    \"x\": x\n",
    "                })\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 4. Step 2: Special handling for Wirecheck (pseudo-IO patches)\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Identify Wirecheck records in our list for NIO-only domain\n",
    "wire_records = [r for r in records if r[\"domain\"] == \"Wirecheck\"]\n",
    "\n",
    "# Define how many pseudo-IO patches you want per original Wirecheck image\n",
    "# (e.g., 3 pseudo-IO patches per image)\n",
    "PSEUDO_IO_PER_IMAGE = 3\n",
    "new_pseudo_records = []\n",
    "\n",
    "# Process each Wirecheck image once\n",
    "processed_images = set()\n",
    "for record in wire_records:\n",
    "    fname = record[\"orig_image\"]\n",
    "    if fname in processed_images:\n",
    "        continue\n",
    "    processed_images.add(fname)\n",
    "    \n",
    "    # Load full image and mask again\n",
    "    img_path = os.path.join(DATA_ROOT, \"Wirecheck\", \"NIO\", fname)\n",
    "    mask_name = os.path.splitext(fname)[0] + \"_mask.png\"\n",
    "    mask_path = os.path.join(DATA_ROOT, \"Wirecheck\", \"Masks\", mask_name)\n",
    "    image_full = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "    mask_full = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    h, w = mask_full.shape\n",
    "    \n",
    "    # Randomly sample background coordinates where mask == 0 for full patches\n",
    "    attempts = 0\n",
    "    found = 0\n",
    "    while found < PSEUDO_IO_PER_IMAGE and attempts < 100:\n",
    "        ry = np.random.randint(0, h - PATCH_SIZE + 1)\n",
    "        rx = np.random.randint(0, w - PATCH_SIZE + 1)\n",
    "        patch_mask = mask_full[ry:ry + PATCH_SIZE, rx:rx + PATCH_SIZE]\n",
    "        if np.all(patch_mask == 0):\n",
    "            # This is a valid background patch\n",
    "            patch_image = image_full[ry:ry + PATCH_SIZE, rx:rx + PATCH_SIZE]\n",
    "            new_pseudo_records.append({\n",
    "                \"img_patch\": patch_image,\n",
    "                \"mask_patch\": np.zeros((PATCH_SIZE, PATCH_SIZE), dtype=np.uint8),\n",
    "                \"label\": 0,  # IO\n",
    "                \"domain\": \"Wirecheck\",\n",
    "                \"orig_image\": fname,\n",
    "                \"y\": ry,\n",
    "                \"x\": rx\n",
    "            })\n",
    "            found += 1\n",
    "        attempts += 1\n",
    "\n",
    "# Append pseudo-IO records to main records list\n",
    "records.extend(new_pseudo_records)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 5. Step 3: Build DataFrame and assign train/val/test splits at image level\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# We need to split per domain, ensuring that all patches from a given orig_image go to same split\n",
    "df[\"split\"] = \"\"  # placeholder\n",
    "\n",
    "split_ratios = {\"train\": 0.7, \"val\": 0.15, \"test\": 0.15}\n",
    "\n",
    "for domain in DOMAINS:\n",
    "    # Get unique image names in this domain\n",
    "    unique_images = df[df[\"domain\"] == domain][\"orig_image\"].unique()\n",
    "    # Shuffle\n",
    "    np.random.shuffle(unique_images)\n",
    "    \n",
    "    n_total = len(unique_images)\n",
    "    n_train = int(split_ratios[\"train\"] * n_total)\n",
    "    n_val = int(split_ratios[\"val\"] * n_total)\n",
    "    \n",
    "    train_imgs = unique_images[:n_train]\n",
    "    val_imgs = unique_images[n_train:n_train + n_val]\n",
    "    test_imgs = unique_images[n_train + n_val:]\n",
    "    \n",
    "    # Assign splits\n",
    "    df.loc[(df[\"domain\"] == domain) & (df[\"orig_image\"].isin(train_imgs)), \"split\"] = \"train\"\n",
    "    df.loc[(df[\"domain\"] == domain) & (df[\"orig_image\"].isin(val_imgs)), \"split\"] = \"val\"\n",
    "    df.loc[(df[\"domain\"] == domain) & (df[\"orig_image\"].isin(test_imgs)), \"split\"] = \"test\"\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 6. Step 4: Save patches as image files and update paths in DataFrame\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "def save_patches(df_split, split_name):\n",
    "    \"\"\"\n",
    "    Save image patches and mask patches to disk and update their paths in the DataFrame.\n",
    "    \"\"\"\n",
    "    split_dir = os.path.join(PATCH_ROOT, split_name)\n",
    "    img_dir = os.path.join(split_dir, \"images\")\n",
    "    mask_dir = os.path.join(split_dir, \"masks\")\n",
    "    \n",
    "    for idx, row in df_split.iterrows():\n",
    "        domain = row[\"domain\"]\n",
    "        orig_img_name = os.path.splitext(row[\"orig_image\"])[0]\n",
    "        y, x = row[\"y\"], row[\"x\"]\n",
    "        label = row[\"label\"]\n",
    "        \n",
    "        # Construct filenames\n",
    "        patch_basename = f\"{domain}_{orig_img_name}_y{y}_x{x}_lbl{label}.png\"\n",
    "        img_output_path = os.path.join(img_dir, patch_basename)\n",
    "        mask_output_path = os.path.join(mask_dir, patch_basename)\n",
    "        \n",
    "        # Save\n",
    "        cv2.imwrite(img_output_path, cv2.cvtColor(row[\"img_patch\"], cv2.COLOR_RGB2BGR))\n",
    "        cv2.imwrite(mask_output_path, row[\"mask_patch\"])\n",
    "        \n",
    "        # Update DataFrame paths\n",
    "        df.at[idx, \"patch_img_path\"] = img_output_path\n",
    "        df.at[idx, \"patch_mask_path\"] = mask_output_path\n",
    "\n",
    "# Apply saving for each split\n",
    "for split_name in [\"train\", \"val\", \"test\"]:\n",
    "    df_split = df[df[\"split\"] == split_name].copy()\n",
    "    save_patches(df_split, split_name)\n",
    "\n",
    "# Keep only necessary columns\n",
    "df_final = df[[\"patch_img_path\", \"patch_mask_path\", \"label\", \"domain\", \"split\"]].copy()\n",
    "\n",
    "# Save DataFrame to CSV for record-keeping\n",
    "df_final.to_csv(\"patches_dataset.csv\", index=False)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 7. Step 5: Define PyTorch Dataset and DataLoader with WeightedRandomSampler\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        PyTorch Dataset for loading image/mask patches based on DataFrame.\n",
    "        \"\"\"\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = cv2.imread(row[\"patch_img_path\"])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(row[\"patch_mask_path\"], cv2.IMREAD_GRAYSCALE)\n",
    "        label = int(row[\"label\"])\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"].unsqueeze(0)  # shape: 1xHxW\n",
    "        \n",
    "        return image, mask, label\n",
    "\n",
    "# Create train DataFrame for DataLoader\n",
    "df_train = df_final[df_final[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "\n",
    "# Compute sample weights based on label imbalance\n",
    "label_counts = df_train[\"label\"].value_counts().to_dict()  # e.g., {0: 1000, 1: 600}\n",
    "weights_for_classes = {cls: 1.0 / count for cls, count in label_counts.items()}\n",
    "sample_weights = [weights_for_classes[row[\"label\"]] for _, row in df_train.iterrows()]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Instantiate Dataset and DataLoader\n",
    "train_dataset = PatchDataset(df_train, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, sampler=sampler, num_workers=4)\n",
    "\n",
    "# For validation and testing (no sampler, just sequential)\n",
    "df_val = df_final[df_final[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "val_dataset = PatchDataset(df_val, transform=A.Compose([\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "]))\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "df_test = df_final[df_final[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "test_dataset = PatchDataset(df_test, transform=A.Compose([\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "]))\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 8. Verification: Print summary of splits and class distribution\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "def print_split_info(df_split, split_name):\n",
    "    total = len(df_split)\n",
    "    class_counts = df_split[\"label\"].value_counts().to_dict()\n",
    "    domain_counts = df_split[\"domain\"].value_counts().to_dict()\n",
    "    print(f\"--- {split_name.upper()} ---\")\n",
    "    print(f\"Total patches: {total}\")\n",
    "    print(f\"Class distribution (0=IO, 1=NIO): {class_counts}\")\n",
    "    print(f\"Domain distribution: {domain_counts}\")\n",
    "    print()\n",
    "\n",
    "print_split_info(df_final[df_final[\"split\"] == \"train\"], \"train\")\n",
    "print_split_info(df_final[df_final[\"split\"] == \"val\"], \"val\")\n",
    "print_split_info(df_final[df_final[\"split\"] == \"test\"], \"test\")\n",
    "\n",
    "# You now have:\n",
    "# - train_loader for balanced training\n",
    "# - val_loader and test_loader for evaluation\n",
    "# - \"patches_dataset.csv\" listing all patch files with labels and splits\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# End of Script\n",
    "# --------------------------------------------------------------------------------\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
